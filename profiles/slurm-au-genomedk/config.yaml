# This profile can be used with a snakemake workflow. Just put this config.yaml-file in a directory called whatever/ and call your snakemake worflow with 
# snakemake --profile whatever/

# ---- Front end stuff ----
local-cores: 16 # front end / head node cores. Most often computing the DAG will be limited by disk-IO anyway.


# ---- Back end stuff ----
cores: 2048 # cluster cores
jobs: 128 # max parallel jobs. Good idea to limit this for dangerous situations.
keep-going: true 
#rerun-incomplete: true
latency-wait: 120 # Some file systems can be slow.
keep-incomplete: false # Should be true for debugging rules.
rerun-triggers: "mtime"


# This one could be cool to have working 
show-failed-logs: true
#jobname: "j_{name}_{jobid}.sh" # Super helpful because it shows the job in qstat


# ---- Conda/Mamba/Apptainer ----
use-conda: true
conda-frontend: 'mamba' # Make sure that you install mamba in the environment where you're calling snakemake. Muuuuch faster than conda.
#use-singularity: true


# ---- AU Genomedk SLURM specifics ----

cluster-cancel: "scancel"

cluster:
  mkdir -p logs/ &&
  sbatch
    --parsable
    --cpus-per-task={threads}
    --mem={resources.mem_mb}
    --job-name=j_{rule}_{wildcards}
    --output=logs/{jobid}-{rule}.out.log
    --error=logs/{jobid}-{rule}.err.log
    --time={resources.runtime}
    --account=ClinicalMicrobio # ClinicalMicrobio or supacow

 
#--partition={resources.partition}
    

default-resources:
  - mem_mb=1024
  #- disk_mb=1024 # genomedk doesn't care 
  - runtime='06:00:00'
  - tmpdir='$SCRATCH'
  #- partition=normal # genomedk doesn't care too much about partitions (https://genome.au.dk/docs/interacting-with-the-queue/#why-is-the-partition-i-chose-being-ignored)
  




