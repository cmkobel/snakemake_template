# This profile can be used with a snakemake workflow. Just put this config.yaml-file in a directory called whatever/ and call your snakemake worflow with 
# snakemake --profile whatever/

# ---- Front end stuff ----
local-cores: 16 # front end / head node cores. Most often computing the DAG will be limited by disk-IO anyway.


# ---- Back end stuff ----
cores: 2048 # cluster cores # Fair play.
jobs: 128 # max parallel jobs. Good idea to limit this for dangerous situations.
keep-going: true 
latency-wait: 120 # Some file systems can be slow.

# Flip these for debugging:
keep-incomplete: false # true for development/debugging
rerun-triggers: "mtime" 


# ---- Logging ----
show-failed-logs: true # This one requires additional configuration beyond the scope of this configuration file.
log-handler-script: "scripts/log_handler_script.py"

    

# ---- Conda/Mamba/Apptainer ----
use-conda: true
conda-frontend: 'mamba' # Make sure that you install mamba in the environment where you're calling snakemake. Muuuuch faster than conda.
#use-singularity: true


# ---- AU Genomedk SLURM specifics ----

cluster-cancel: "scancel"

cluster:
  sbatch
    --parsable
    --cpus-per-task={threads}
    --mem={resources.mem_mb}
    --job-name=st-{rule}_{wildcards}
    --output=logs/{jobid}-{rule}.out.log
    --error=logs/{jobid}-{rule}.err.log
    --time={resources.runtime}
    --account=ClinicalMicrobio # ClinicalMicrobio or supacow

 
#--partition={resources.partition}
    

default-resources:
  - mem_mb=1024
  #- disk_mb=1024 # genomedk doesn't care 
  - runtime='12:00:00'
  - tmpdir='$SCRATCH'
  #- partition=normal # genomedk doesn't care too much about partitions (https://genome.au.dk/docs/interacting-with-the-queue/#why-is-the-partition-i-chose-being-ignored)
  




