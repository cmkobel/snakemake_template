# This profile can be used with a snakemake workflow. Just put this config.yaml-file in a directory called whatever/ and call your snakemake worflow with 
# snakemake --profile whatever/

# ---- Front end stuff ----
local-cores: 16 # front end / head node cores. Most often computing the DAG will be limited by disk-IO anyway.


# ---- Back end stuff ----
cores: 2048 # cluster cores # Fair play.
jobs: 128 # max parallel jobs. Good idea to limit this for dangerous situations.
keep-going: true 
latency-wait: 120 # Some file systems can be slow.

# Flip these for debugging:
keep-incomplete: false # true for development/debugging
rerun-triggers: "mtime" 


# ---- Logging ----
show-failed-logs: true # This one requires additional configuration beyond the scope of this configuration file.
log-handler-script: "scripts/log_handler_script.py"
jobname: "j_{name}_{jobid}.sh" # Super helpful because it shows the job in qstat


# ---- Conda/Mamba/Apptainer ----
use-conda: true
conda-frontend: 'mamba' # Make sure that you install mamba in the environment where you're calling snakemake. Muuuuch faster than conda.
#use-singularity: true


# ---- QUT CMR Lyra specifics ----

cluster-cancel: "qdel"

cluster:
  qsub 
    -V 
    -A kobel 
    -q microbiome 
    -N st-{rule}_{wildcards}
    -e logs/{jobid}-{rule}.err.log 
    -o logs/{jobid}-{rule}.out.log
    -l select=1:ncpus={threads}:mem={resources.mem_mb}mb,walltime={resources.runtime} 


default-resources:
  - mem_mb=1024
  - runtime='12:00:00'
  #- tmpdir='$SCRATCH' # Not always necessary.
  #- disk_mb=1024 # Not always necessary.
  #- partition=normal # Not always necessary.
  
  
